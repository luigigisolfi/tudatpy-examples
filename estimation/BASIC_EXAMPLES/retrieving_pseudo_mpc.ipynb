{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47ef2b9-d558-4ed6-b9da-76363076e27c",
   "metadata": {},
   "source": [
    "# Retrieving Pseudo-MPC Observations for JUICE\n",
    "\n",
    "## Objectives\n",
    "In this example show how to retrieve pseudo-MPEC data from a selected webpage. We will use the Tudat Horizons interface to compare observation ouput and load the standard SPICE kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6778f-b115-41e9-bcbf-f67cd3f00387",
   "metadata": {},
   "source": [
    "## Key API References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd531678-d83c-4eb0-95c1-215838803ed4",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877104e-b320-46e3-977d-da69c0117b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tudatpy.data.mpc import BatchMPC\n",
    "from tudatpy.kernel.numerical_simulation import environment_setup\n",
    "from tudatpy.kernel.numerical_simulation.estimation_setup import observation\n",
    "from tudatpy.kernel.interface import spice\n",
    "from tudatpy.kernel import numerical_simulation\n",
    "from tudatpy.data.horizons import HorizonsQuery\n",
    "from tudatpy.astro import element_conversion\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from tudatpy.kernel.numerical_simulation import environment_setup\n",
    "from tudatpy.kernel.numerical_simulation import propagation_setup\n",
    "from tudatpy.kernel.numerical_simulation import estimation, estimation_setup\n",
    "from tudatpy.kernel.numerical_simulation.estimation_setup import observation\n",
    "\n",
    "# Load spice kernels\n",
    "spice.load_standard_kernels()\n",
    "\n",
    "# Load spice kernels\n",
    "path = os.getcwd()\n",
    "kernels = [path+'/juice_orbc_000073_230414_310721_v01.bsp']\n",
    "spice.load_standard_kernels(kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6af8b8-721b-4fe2-9cd4-818f56406ee8",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "Unlike what already done in the example [Retrieving_mpc_observation_data (ADD LINK)](), we cannout initialize the BatchMPC object yet, since astroquery...is not linked to Bill Gray's html page. We therefore need to \n",
    "\n",
    "1) parse B.G.'s html page containing the data, and retrieve the information needed (obs. time, angular observables, station codes, obs. band, etc...).\n",
    "2) feed this information into a table that is similar to the one created (in the other example) using the `.get_observations()` method.\n",
    "3) convert the newly created table into a `Batch.MPC` object using `.from_astropy()` .\n",
    "\n",
    "### 1) Parsing the html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b954d-6a23-462e-bda9-e4b2bdc9aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mpc import MPC\n",
    "import requests\n",
    "import re\n",
    "from tudatpy import constants\n",
    "\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table, Column\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "MPC.query_object = requests.get(\"https://www.projectpluto.com/pluto/mpecs/23053a.htm\", \"-28\")\n",
    "\n",
    "observations = MPC.query_object.text #use this if you want the whole html page\n",
    "# Find the position of the <a name=\"stations\"></a> tag\n",
    "match = re.search(r'<a name=\"stations\"></a>', observations)\n",
    "if match:\n",
    "    # Keep only the part of the HTML before the matched line\n",
    "    html_cleaned = observations[:match.start()]\n",
    "    #print(html_cleaned)\n",
    "match = re.search(r'<a href=\"https://www.projectpluto.com/mpec_xpl.htm#astrometry\"> <b>Astrometry:</b> </a>', html_cleaned)\n",
    "if match:\n",
    "    # Keep only the part of the HTML before the matched line\n",
    "    html_cleaned = html_cleaned[match.end():].lstrip()\n",
    "observations = [line.strip() for line in html_cleaned.splitlines() if line.strip()]\n",
    "\n",
    "# Initialize lists to hold the extracted data\n",
    "numbers = []\n",
    "epochs = []\n",
    "RAs = []\n",
    "DECs = []\n",
    "bands = []\n",
    "observatories = []\n",
    "\n",
    "for i,observation_string in enumerate(observations):\n",
    "    soup = BeautifulSoup(observation_string, 'html.parser')\n",
    "\n",
    "    number = i+1\n",
    "    #print(f'observation n. {number}')\n",
    "\n",
    "    # Extract the observation string (without the band and observatory)\n",
    "    observation_string = soup.get_text().split(soup.find_all('a')[1].get_text())[1].split(soup.find_all('a')[2].get_text())[0].strip()\n",
    "    print(observation_string)\n",
    "    if observation_string[2] == 'K':\n",
    "        #rint('no can do')\n",
    "        continue\n",
    "        \n",
    "    # Extract and parse date and time\n",
    "    if observation_string[0:2] == 'KC' or observation_string[0:2] == '0C' or observation_string[0:2] == '3C' or observation_string[0:2] == 'KB':\n",
    "        year = observation_string[2:6]  # Year (e.g., 2023)\n",
    "        month = observation_string[7:9]  # Month (e.g., 04)\n",
    "        #print(month)\n",
    "        date_part, frac_day = observation_string[10:19].split('.')\n",
    "        #print(f'Day:{date_part}, Fraction of Day:{frac_day}')\n",
    "        numbers.append(number)\n",
    "    elif observation_string[0] == 'C':\n",
    "        year = observation_string[1:5]  # Year (e.g., 2023)\n",
    "        month = observation_string[6:8]  # Month (e.g., 04)\n",
    "        #print(month)\n",
    "        date_part, frac_day = observation_string[9:18].split('.')\n",
    "        #print(f'Day:{date_part}, Fraction of Day:{frac_day}')\n",
    "        numbers.append(number)\n",
    "    \n",
    "\n",
    "    # Calculate the time in hours, minutes, seconds\n",
    "    hours = float(\"0.\" + frac_day) * 24\n",
    "    minutes = (hours % 1) * 60\n",
    "    seconds = (minutes % 1) * 60\n",
    "    seconds_int = int(seconds)\n",
    "    microseconds = int((seconds - seconds_int) * 1_000_000)\n",
    "    \n",
    "    if round(seconds) == 60: \n",
    "        minutes = minutes + 1\n",
    "        seconds = 0\n",
    "    #print(f'Hours:{hours}, Minutes:{minutes}, Seconds:{seconds}')\n",
    "    # Convert to Julian date\n",
    "    time_string = f\"{date_part} {int(hours):02}:{int(minutes):02}:{seconds:02}\"\n",
    "    epoch = f'{year}-{month}-{date_part} {int(hours):02}:{int(minutes):02}:{seconds_int:02}.{microseconds:06}'\n",
    "    #print(f'Epoch:{epoch}')\n",
    "    dt = datetime.strptime(epoch, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    dt_jd = Time(dt).jd\n",
    "    epochs.append(dt_jd)\n",
    "\n",
    "\n",
    "    # Extract RA and DEC\n",
    "    if observation_string[0:2] == 'KC' or observation_string[0:2] == '0C' or observation_string[0:2] == '3C' or observation_string[0:2] == 'KB':\n",
    "        ra_dec_str = observation_string[19:45]  # RA and DEC part\n",
    "        #print(f'ra & dec str:{ra_dec_str}')\n",
    "        ra_part = ra_dec_str[:12].strip()  # Right Ascension\n",
    "        #print(f'ra part: {ra_part}')\n",
    "        dec_part = ra_dec_str[12:].strip()  # Declination (considering no space if negative)\n",
    "        #print(f'dec part:{dec_part}')\n",
    "\n",
    "        #Right Ascension\n",
    "        parts_RA = ra_part.split()\n",
    "        hours_RA = float(parts_RA[0])\n",
    "        minutes_RA = float(parts_RA[1]) if len(parts_RA) > 1 else 0\n",
    "        seconds_RA = float(parts_RA[2]) if len(parts_RA) > 2 else 0\n",
    "        deg_ra = 15*hours_RA + 0.25*minutes_RA + seconds_RA/240\n",
    "\n",
    "        #Declination\n",
    "        parts_DEC = dec_part.split()\n",
    "        degrees_DEC = float(parts_DEC[0])\n",
    "        minutes_DEC = float(parts_DEC[1]) if len(parts_DEC) > 1 else 0\n",
    "        seconds_DEC = float(parts_DEC[2]) if len(parts_DEC) > 2 else 0\n",
    "        if len(parts_DEC[0]) == 3:\n",
    "            deg_dec = - (abs(degrees_DEC) + minutes_DEC / 60 + seconds_DEC / 3600)\n",
    "        else:\n",
    "            deg_dec = (abs(degrees_DEC) + minutes_DEC/ 60 + seconds_DEC/ 3600)\n",
    "        #print(f'deg_ra {deg_ra}')\n",
    "        #print(f'deg_dec {deg_dec}')\n",
    "        # Extract Band\n",
    "        band = observation_string[57:58]\n",
    "\n",
    "        bands.append(band)\n",
    "\n",
    "    elif observation_string[0] == 'C':\n",
    "        ra_dec_str = observation_string[18:45]  # RA and DEC part\n",
    "        #print(f'ra & dec str:{ra_dec_str}')\n",
    "        ra_part = ra_dec_str[:12].strip()  # Right Ascension\n",
    "        #print(f'ra part: {ra_part}')\n",
    "        dec_part = ra_dec_str[12:].strip()  # Declination (considering no space if negative)\n",
    "        print(f'dec part:{dec_part}')\n",
    "\n",
    "        #Right Ascension\n",
    "        parts_RA = ra_part.split()\n",
    "        hours_RA = float(parts_RA[0])\n",
    "        minutes_RA = float(parts_RA[1]) if len(parts_RA) > 1 else 0\n",
    "        seconds_RA = float(parts_RA[2]) if len(parts_RA) > 2 else 0\n",
    "        #print(hours_RA, minutes_RA, seconds_RA)\n",
    "        deg_ra = 15*hours_RA + 0.25*minutes_RA + seconds_RA/240\n",
    "\n",
    "        #Declination\n",
    "        parts_DEC = dec_part.split()\n",
    "        degrees_DEC = float(parts_DEC[0])\n",
    "        minutes_DEC = float(parts_DEC[1]) if len(parts_DEC) > 1 else 0\n",
    "        seconds_DEC = float(parts_DEC[2]) if len(parts_DEC) > 2 else 0\n",
    "        if len(parts_DEC[0]) == 3:\n",
    "            deg_dec = - (abs(degrees_DEC) + minutes_DEC/ 60 + seconds_DEC/ 3600)\n",
    "        else:\n",
    "            deg_dec = (abs(degrees_DEC) + minutes_DEC/ 60 + seconds_DEC/ 3600)\n",
    "        #print(f'deg_ra: {deg_ra}')\n",
    "        #print(f'deg_dec {deg_dec}')\n",
    "        # Extract Band\n",
    "        band = observation_string[57:58]\n",
    "\n",
    "        bands.append(band)\n",
    "\n",
    "    # Extract the observatory code\n",
    "    observatory = soup.find_all('a')[2].get_text().strip()\n",
    "    observatories.append(observatory)\n",
    "    rad_ra = (np.radians(deg_ra) + np.pi) % (2*np.pi) - np.pi\n",
    "    RAs.append(np.degrees(rad_ra)) #this is in degrees\n",
    "    DECs.append(deg_dec) #this is in degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171ca96-bd2b-4403-8f93-b38be86a4176",
   "metadata": {},
   "source": [
    "### 2) Feeding the table\n",
    "Note that RA and Dec are given in **degrees** (they could be given in radians, but we leave it this way to be consistent with the previous JUICE example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45f3bd-9ec0-4139-924c-12c6591fbd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table\n",
    "table = Table()\n",
    "\n",
    "# Add columns to the table\n",
    "table.add_column(Column(name='number', data= np.transpose(['-28']*len(numbers))))\n",
    "table.add_column(Column(name='designation', data= np.transpose(['JUICE']*len(numbers))))\n",
    "table.add_column(Column(name='discovery', data= np.transpose(['NaN']*len(numbers))))\n",
    "table.add_column(Column(name='note1', data= np.transpose(['NaN']*len(numbers))))\n",
    "table.add_column(Column(name='note2', data= np.transpose(['NaN']*len(numbers))))\n",
    "table.add_column(Column(name='epoch', data=epochs))\n",
    "table.add_column(Column(name='RA', data=RAs, unit='deg'))  # RA in degrees\n",
    "table.add_column(Column(name='DEC', data=DECs, unit='deg'))  # DEC in degrees\n",
    "table.add_column(Column(name='mag', data=np.transpose(['NaN']*len(numbers))))\n",
    "table.add_column(Column(name='band', data=bands))\n",
    "table.add_column(Column(name='observatory', data=observatories))\n",
    "\n",
    "# Display the table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e9fa7-ee26-49d1-9ab6-bd2ffb737c92",
   "metadata": {},
   "source": [
    "### Creating the BatchMPC object\n",
    "Note that batch1.table.query always gives the result in **radians**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccad2b6-47c9-4d00-81f2-f8aaf15b10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = BatchMPC()\n",
    "batch1.from_astropy(table, in_degrees = True)\n",
    "batch1.summary()\n",
    "\n",
    "batch1.filter(\n",
    "    epoch_start=datetime(2024, 7, 1)\n",
    ")\n",
    "\n",
    "print(batch1.table)\n",
    "print(batch1.observatories_table(only_in_batch=True, only_space_telescopes=False, include_positions=False))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98025c9-0223-4834-aa3f-dfa5fabb2b41",
   "metadata": {},
   "source": [
    "### Retrieve Observation Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b3d08-caf5-4aa3-b484-93887cd81bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the bodies for our environment\n",
    "\"\"\"\n",
    "A system of bodies must be created to keep observatories' positions consistent with Earth's shape model and to allow the attachment of these observatories to Earth. For the purposes of this example, we keep it as simple as possible. See the [Estimation with MPC](https://docs.tudat.space/en/latest/_src_getting_started/_src_examples/notebooks/estimation/estimation_with_mpc.html) for a more complete setup and explanation appropriate for estimation. For our bodies, we only use Earth and the Sun. We set our origin to `\"SSB\"`, the solar system barycenter. We use the default body settings from the `SPICE` kernel to initialise the planet and use it to create a system of bodies. This system of bodies is used in the `to_tudat()` method.\n",
    "\"\"\"\n",
    "\n",
    "bodies_to_create = [\n",
    "    \"Sun\", \n",
    "    \"Earth\", \n",
    "    \"Moon\", \n",
    "    \"Jupiter\", \n",
    "    \"Saturn\", \n",
    "    \"Mars\", \n",
    "    \"Mercury\", \n",
    "    \"Neptune\", \n",
    "    \"Uranus\", \n",
    "    \"Venus\"\n",
    "]\n",
    "\n",
    "# Create default body settings\n",
    "global_frame_origin = \"Earth\"\n",
    "global_frame_orientation = \"J2000\"\n",
    "\n",
    "body_settings = environment_setup.get_default_body_settings(\n",
    "    bodies_to_create, global_frame_origin, global_frame_orientation)\n",
    "\n",
    "\n",
    "# Create system of bodies\n",
    "bodies = environment_setup.create_system_of_bodies(body_settings)\n",
    "\n",
    "# Retrieve JUICE' body name from BatchMPC and set its centre to enable its propapgation\n",
    "bodies_to_propagate = batch1.MPC_objects\n",
    "central_bodies = [global_frame_origin]\n",
    "\n",
    "# Now that our batch is ready, we can transform it to a Tudat `ObservationCollection` object using the `to_tudat()` method.\n",
    "#\n",
    "# The `.to_tudat()` does the following for us:\n",
    "#\n",
    "# 1. Creates an empty body for each minor planet with their MPC code as a name.\n",
    "# 2. Adds this body to the system of bodies inputted to the method.\n",
    "# 3. Retrieves the global position of the terrestrial observatories in the batch and adds these stations to the Tudat environment.\n",
    "# 4. Creates link definitions between each unique terrestrial observatory/ minor planet combination in the batch.\n",
    "# 5. (Optionally) creates a link definition between each space telescope / minor planet combination in the batch. This requires an addional input.\n",
    "# 6. Creates a `SingleObservationSet` object for each unique link that includes all observations for that link.\n",
    "# 7. Returns an `ObservationCollection` object.\n",
    "# 7. Returns an `ObservationCollection` object.#Create the observation collection \n",
    "\n",
    "observation_collection = batch1.to_tudat(bodies, included_satellites=None, apply_star_catalog_debias = False)\n",
    "\n",
    "print(np.degrees(observation_collection.concatenated_observations))\n",
    "#\n",
    "# If our batch includes space telescopes like WISE and TESS we must either link their Tudat name or exclude them. For now we exclude them by setting `included_satellites` to `None`. The additional features section shows an example of how to link satellites to the `to_tudat()` method. The '.to_tudat()' method does not alter the batch object itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e46722-d798-432f-8098-9a1bcb67c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now retrieve the links from the ObservationCollection we got from `.to_tudat()` and we can create settings for these links. This is where link biases would be set, for now we just keep the settings default.\n",
    "\n",
    "observation_settings_list = list()\n",
    "\n",
    "link_list = list(\n",
    "    observation_collection.get_link_definitions_for_observables(\n",
    "        observable_type=observation.angular_position_type\n",
    "    )\n",
    ")\n",
    "\n",
    "for link in link_list:\n",
    "    # add optional bias settings\n",
    "    observation_settings_list.append(\n",
    "        observation.angular_position(link, bias_settings=None)\n",
    "    )\n",
    "\n",
    "# Retrieve MPC observation times, RA and DEC\n",
    "batch_times = batch1.table.epochJ2000secondsTDB.to_list()\n",
    "batch_times_utc = batch1.table.epochUTC.to_list()\n",
    "batch_RA = batch1.table.RA #in radians\n",
    "batch_DEC = batch1.table.DEC #in radians\n",
    "\n",
    "\n",
    "# Create Horizons query, see Horizons Documentation for more info.\n",
    "JUICE_horizons_query = HorizonsQuery(\n",
    "    query_id=\"-28\",\n",
    "    location=\"500@399\",  # geocenter @ Earth\n",
    "    epoch_list=batch_times,\n",
    "    extended_query=True,\n",
    ")\n",
    "\n",
    "# retrieve JPL observations\n",
    "jpl_observations = JUICE_horizons_query.interpolated_observations()\n",
    "#print(jpl_observations)\n",
    "jpl_RA = jpl_observations[:, 1] % np.pi - np.pi\n",
    "#print(jpl_RA % np.pi - np.pi)\n",
    "jpl_DEC = jpl_observations[:,2]\n",
    "\n",
    "#print(jpl_DEC[:1000] - batch_DEC[:1000])\n",
    "#print(batch_times -jpl_observations[:, 0] )\n",
    "max_diff_RA = np.abs(jpl_RA - batch_RA).max()\n",
    "max_diff_DEC = np.abs(jpl_DEC - batch_DEC).max()\n",
    "min_diff_RA = np.abs(jpl_RA - batch_RA).min()\n",
    "min_diff_DEC = np.abs(jpl_DEC - batch_DEC).min()\n",
    "print(\"Maximum difference between Interpolated Horizons data and MPC observations:\")\n",
    "print(f\"Right Ascension: {np.round(max_diff_RA, 10)} rad\")\n",
    "print(f\"Declination: {np.round(max_diff_DEC, 10)} rad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a27544-59f1-42db-a6e8-7ef907c944d8",
   "metadata": {},
   "source": [
    "## Plot Residuals with JPL Horizons, Observations in the Sky and Observations Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178d38a-a046-446e-9bb1-a8b06186bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot\n",
    "fig, (ax_ra, ax_dec) = plt.subplots(2, 1, figsize=(11, 6), sharex=True)\n",
    "\n",
    "#print(f'RA residuals:\\n {jpl_RA - batch_RA}')\n",
    "#print(f'DEC residuals:\\n + {jpl_DEC-batch_DEC}')\n",
    "\n",
    "ax_ra.scatter(batch_times_utc, (jpl_RA - batch_RA), marker=\"+\")\n",
    "ax_dec.scatter(batch_times_utc, (jpl_DEC - batch_DEC), marker=\"+\")\n",
    "\n",
    "ax_ra.set_ylabel(\"Error [rad]\")\n",
    "ax_dec.set_ylabel(\"Error [rad]\")\n",
    "ax_dec.set_xlabel(\"Date\")\n",
    "\n",
    "ax_ra.grid()\n",
    "ax_dec.grid()\n",
    "\n",
    "ax_ra.set_title(\"Right Ascension\")\n",
    "ax_dec.set_title(\"Declination\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### Plotting observations\n",
    "\"\"\"\n",
    "The `.plot_observations_sky()` method can be used to view a projection of the observations. Similarly, `.plot_observations_temporal()` shows the declination and right ascension of a batch's bodies over time.\n",
    "\"\"\"\n",
    "\n",
    "#print(f'batch_RA in radians from table.query: \\n\\n{batch_RA}') \n",
    "#print(f'batch_RA in degrees: \\n\\n{np.degrees(batch_RA)}') \n",
    "#print(f'batch_DEC in radians from table.query: \\n\\n{batch_DEC}') \n",
    "#print(f'batch_DEC in degrees: \\n\\n{np.degrees(batch_DEC)}') \n",
    "\n",
    "# Try some of the other projections: 'hammer', 'mollweide' and 'lambert'\n",
    "fig = batch1.plot_observations_sky()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6eab31-b95b-47c7-b583-17824ed0073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tudatpy.util import result2array\n",
    "\n",
    "# Retrieve the first and final observation epochs and add the buffer\n",
    "epoch_start_nobuffer = batch1.epoch_start\n",
    "epoch_end_nobuffer = batch1.epoch_end\n",
    "\n",
    "print(f'Epoch Start (no buffer): {epoch_start_nobuffer}')\n",
    "print(f'Epoch End (no buffer): {epoch_end_nobuffer}')\n",
    "\n",
    "time_buffer = 86400\n",
    "\n",
    "#number of iterations for our estimation\n",
    "number_of_estimation_iterations = 8\n",
    "\n",
    "# timestep of 300s for our estimation\n",
    "timestep_global = 60*5\n",
    "\n",
    "epoch_start_buffer = epoch_start_nobuffer - time_buffer \n",
    "epoch_end_buffer = epoch_end_nobuffer + time_buffer \n",
    "\n",
    "print(f'Epoch Start (with buffer): {epoch_start_buffer}')\n",
    "print(f'Epoch End (with buffer): {epoch_end_buffer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb05d00-351e-4868-8de6-c794cbfc03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create radiation pressure settings\n",
    "reference_area_radiation = 85 #m^2\n",
    "radiation_pressure_coefficient = 1.2\n",
    "occulting_bodies = ['Moon', 'Earth']\n",
    "radiation_pressure_settings = environment_setup.radiation_pressure.cannonball(\n",
    "    \"Sun\", reference_area_radiation, radiation_pressure_coefficient, occulting_bodies\n",
    ")\n",
    "# Add the radiation pressure interface to the environment\n",
    "environment_setup.add_radiation_pressure_interface(bodies, \"-28\", radiation_pressure_settings)\n",
    "\n",
    "\n",
    "# Define accelerations\n",
    "accelerations = {\n",
    "    \"Sun\": [\n",
    "        propagation_setup.acceleration.point_mass_gravity(),\n",
    "        propagation_setup.acceleration.relativistic_correction(use_schwarzschild=True),\n",
    "        propagation_setup.acceleration.cannonball_radiation_pressure(),\n",
    "    ],\n",
    "    \"Mercury\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "    \"Venus\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "    \"Earth\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "    \"Moon\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "    \"Mars\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "    \"Jupiter\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "    \"Saturn\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "    \"Uranus\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "    \"Neptune\": [propagation_setup.acceleration.point_mass_gravity()],\n",
    "}\n",
    "\n",
    "# Set up the accelerations settings for each body, in this case only JUICE\n",
    "acceleration_settings = {}\n",
    "for body in batch1.MPC_objects:\n",
    "    acceleration_settings[str(body)] = accelerations\n",
    "\n",
    "acceleration_settings\n",
    "# create the acceleration models.\n",
    "acceleration_models = propagation_setup.create_acceleration_models(\n",
    "    bodies, acceleration_settings, bodies_to_propagate, central_bodies\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c90541-68e8-45dc-89a6-6b288fa19f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 1\n",
    "\n",
    "initial_position_offset = 0\n",
    "initial_velocity_offset = 0\n",
    "\n",
    "ephemeris_states = JUICE_horizons_query.cartesian('J2000')\n",
    "\n",
    "spice_states = []\n",
    "for epoch in batch_times:\n",
    "    state = spice.get_body_cartesian_state_at_epoch(\n",
    "        '-28',\n",
    "        global_frame_origin,\n",
    "        global_frame_orientation,\n",
    "        \"NONE\",\n",
    "        epoch,\n",
    "    )\n",
    "\n",
    "    spice_states.append(state)\n",
    "\n",
    "\n",
    "initial_state = ephemeris_states[0,1:]\n",
    "\n",
    "initial_state_spice = spice_states[0]\n",
    "print(batch_times[0])\n",
    "print(ephemeris_states[0,0])\n",
    "\n",
    "print(initial_state)\n",
    "print(initial_state_spice)\n",
    "initial_guess = initial_state.copy()\n",
    "initial_guess[0:3] += (2 * np.random.rand(3) - 1) * initial_position_offset\n",
    "initial_guess[3:6] += (2 * np.random.rand(3) - 1) * initial_velocity_offset\n",
    "\n",
    "initial_guess_spice = initial_state_spice.copy()\n",
    "initial_guess_spice[0:3] += (2 * np.random.rand(3) - 1) * initial_position_offset\n",
    "initial_guess_spice[3:6] += (2 * np.random.rand(3) - 1) * initial_velocity_offset\n",
    "\n",
    "print(\"Error between the real initial state and our initial guess:\")\n",
    "print(initial_guess - initial_state)\n",
    "print(initial_guess_spice - initial_state_spice)\n",
    "\n",
    "\n",
    "x_horizons = [state[1] for state in ephemeris_states]\n",
    "y_horizons = [state[2] for state in ephemeris_states]\n",
    "z_horizons = [state[3] for state in ephemeris_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad094c9-ab33-4f47-8655-30aad45ff294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numerical integrator settings\n",
    "integrator_settings = propagation_setup.integrator.\\\n",
    "    runge_kutta_fixed_step_size(initial_time_step=timestep_global,\n",
    "                                coefficient_set=propagation_setup.integrator.CoefficientSets.rkdp_87)\n",
    "\n",
    "# Terminate at the time of oldest observation\n",
    "termination_condition = propagation_setup.propagator.time_termination(epoch_end_buffer)\n",
    "\n",
    "# Create propagation settings\n",
    "propagator_settings = propagation_setup.propagator.translational(\n",
    "    central_bodies=['Earth'],\n",
    "    acceleration_models=acceleration_models,\n",
    "    bodies_to_integrate=bodies_to_propagate,\n",
    "    initial_states=initial_guess,\n",
    "    initial_time=epoch_start_buffer,\n",
    "    integrator_settings=integrator_settings,\n",
    "    termination_settings=termination_condition,\n",
    ")\n",
    "\n",
    "# Create propagation settings\n",
    "propagator_settings_spice = propagation_setup.propagator.translational(\n",
    "    central_bodies=['Earth'],\n",
    "    acceleration_models=acceleration_models,\n",
    "    bodies_to_integrate=bodies_to_propagate,\n",
    "    initial_states=initial_guess_spice,\n",
    "    initial_time=epoch_start_buffer,\n",
    "    integrator_settings=integrator_settings,\n",
    "    termination_settings=termination_condition,\n",
    ")\n",
    "\n",
    "print(central_bodies)\n",
    "print(acceleration_models)\n",
    "print(bodies_to_propagate)\n",
    "print(initial_guess)\n",
    "print(epoch_start_buffer)\n",
    "print(integrator_settings)\n",
    "print(termination_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303aaac-e7e6-4a1f-a27a-b1b6fbd9c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VEHICLE BODY ###\n",
    "# Create vehicle object\n",
    "bodies.get(\"-28\").mass = 1800 #kg\n",
    "\n",
    "# Create simulation object and propagate the dynamics\n",
    "dynamics_simulator = numerical_simulation.create_dynamics_simulator(\n",
    "    bodies, propagator_settings\n",
    ")\n",
    "\n",
    "dynamics_simulator_spice = numerical_simulation.create_dynamics_simulator(\n",
    "    bodies, propagator_settings_spice\n",
    ")\n",
    "# Extract the resulting state history and convert it to an ndarray\n",
    "states = dynamics_simulator.propagation_results.state_history\n",
    "states_array = result2array(states)\n",
    "\n",
    "states_spice = dynamics_simulator_spice.propagation_results.state_history\n",
    "states_array_spice = result2array(states_spice)\n",
    "print(states_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22cee9-e53d-4394-8467-2c938d04e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_prop = [state[0] for state in states_array]\n",
    "\n",
    "x_prop = [state[1] for state in states_array]\n",
    "y_prop = [state[2] for state in states_array]\n",
    "z_prop = [state[3] for state in states_array]\n",
    "\n",
    "\n",
    "time_prop_spice = [state[0] for state in states_array_spice]\n",
    "\n",
    "x_prop_spice = [state[1] for state in states_array_spice]\n",
    "y_prop_spice = [state[2] for state in states_array_spice]\n",
    "z_prop_spice = [state[3] for state in states_array_spice]\n",
    "\n",
    "print(initial_state_spice[0])\n",
    "print(x_prop_spice[0])\n",
    "\n",
    "x_spice = [state[0] for state in spice_states]\n",
    "y_spice= [state[1] for state in spice_states]\n",
    "z_spice= [state[2] for state in spice_states]\n",
    "\n",
    "plt.scatter(batch_times, x_horizons, s = 15, label = 'x horizons')\n",
    "plt.scatter(batch_times, y_horizons, s = 15, label = 'y horizons')\n",
    "plt.scatter(batch_times, z_horizons, s = 15, label = 'z horizons')\n",
    "\n",
    "plt.scatter(time_prop, x_prop, s = 1, label = 'x prop')\n",
    "plt.scatter(time_prop, y_prop, s = 1, label = 'y prop')\n",
    "plt.scatter(time_prop, z_prop, s = 1, label = 'z prop')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(batch_times, x_spice, s = 15, label = 'x spice')\n",
    "plt.scatter(batch_times, y_spice, s = 15, label = 'y spice')\n",
    "plt.scatter(batch_times, z_spice, s = 15, label = 'z spice')\n",
    "\n",
    "plt.scatter(time_prop_spice, x_prop_spice, s = 1, label = 'x prop')\n",
    "plt.scatter(time_prop_spice, y_prop_spice, s = 1, label = 'y prop')\n",
    "plt.scatter(time_prop_spice, z_prop_spice, s = 1, label = 'z prop')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "states_array[:]\n",
    "print(\"Error between the real spice final state and our final state:\")\n",
    "print(states_array[-1][1:] - ephemeris_states[-1][1:])\n",
    "print(states_array_spice[-1][1:] - spice_states[-1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49d21e-a9c4-4013-8ef9-ced2b030b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters settings to propagate the state transition matrix\n",
    "parameter_settings = estimation_setup.parameter.initial_states(\n",
    "    propagator_settings, bodies\n",
    ")\n",
    "\n",
    "# Create the parameters that will be estimated\n",
    "parameters_to_estimate = estimation_setup.create_parameter_set(\n",
    "    parameter_settings, bodies, propagator_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284f7ff-8ca8-489b-9058-0d75de4c6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the estimator\n",
    "estimator = numerical_simulation.Estimator(\n",
    "    bodies=bodies,\n",
    "    estimated_parameters=parameters_to_estimate,\n",
    "    observation_settings=observation_settings_list,\n",
    "    propagator_settings=propagator_settings,\n",
    "    integrate_on_creation=True,\n",
    ")\n",
    "\n",
    "# Save the true parameters to later analyse the error\n",
    "truth_parameters = parameters_to_estimate.parameter_vector\n",
    "\n",
    "# provide the observation collection as input, and limit number of iterations for estimation.\n",
    "estimation_input = estimation.EstimationInput(\n",
    "    observations_and_times=observation_collection,\n",
    "    convergence_checker=estimation.estimation_convergence_checker(\n",
    "        maximum_iterations=7,\n",
    "    ),\n",
    ")\n",
    "\n",
    "estimation_input.define_estimation_settings(\n",
    "    reintegrate_variational_equations=False,\n",
    "    save_state_history_per_iteration=True)\n",
    "\n",
    "estimation_output = estimator.perform_estimation(estimation_input)\n",
    "residual_history = estimation_output.residual_history\n",
    "\n",
    "print(estimation_output.simulation_results_per_iteration[-1])\n",
    "\n",
    "###??????????\n",
    "print(truth_parameters - parameters_to_estimate.parameter_vector)\n",
    "\n",
    "\n",
    "earth_gravitational_parameter = bodies.get(\"Earth\").gravitational_parameter\n",
    "oe = element_conversion.cartesian_to_keplerian(\n",
    "    cartesian_elements = parameters_to_estimate.parameter_vector,\n",
    "    gravitational_parameter=earth_gravitational_parameter\n",
    ")\n",
    "\n",
    "print(f'Semi-Parameter:{oe[0]}')\n",
    "print(f'f-element:{oe[1]}')\n",
    "print(f'g-element:{np.degrees(oe[2])}')\n",
    "print(f'h_element:{np.degrees(oe[3])}')\n",
    "print(f'k-element:{np.degrees(oe[4])}')\n",
    "print(f'True Longitude:{np.degrees(oe[5])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed51445-d6c4-4a8f-af1a-2f0313e92c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of columns and rows for our plot\n",
    "number_of_columns = 2\n",
    "\n",
    "number_of_rows = (\n",
    "    int(number_of_estimation_iterations / number_of_columns)\n",
    "    if number_of_estimation_iterations % number_of_columns == 0\n",
    "    else int((number_of_estimation_iterations + 1) / number_of_columns)\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    number_of_rows,\n",
    "    number_of_columns,\n",
    "    figsize=(9, 3.5 * number_of_rows),\n",
    "    sharex=True,\n",
    "    sharey=False,\n",
    ")\n",
    "\n",
    "# We cheat a little to get an approximate year out of our times (which are in seconds since J2000)\n",
    "residual_times = (\n",
    "    np.array(observation_collection.concatenated_times) / (86400 * 365.25) + 2000\n",
    ")\n",
    "\n",
    "\n",
    "# plot the residuals, split between RA and DEC types\n",
    "for idx, ax in enumerate(fig.get_axes()):\n",
    "    ax.grid()\n",
    "    # we take every second\n",
    "    ax.scatter(\n",
    "        residual_times[::2],\n",
    "        residual_history[\n",
    "            ::2,\n",
    "            idx,\n",
    "        ],\n",
    "        marker=\"+\",\n",
    "        s=60,\n",
    "        label=\"Right Ascension\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        residual_times[1::2],\n",
    "        residual_history[\n",
    "            1::2,\n",
    "            idx,\n",
    "        ],\n",
    "        marker=\"*\",\n",
    "        s=60,\n",
    "        label=\"Declination\",\n",
    "    )\n",
    "    ax.set_ylabel(\"Observation Residual [rad]\")\n",
    "    ax.set_title(\"Iteration \" + str(idx + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# add the year label for the x-axis\n",
    "for col in range(number_of_columns):\n",
    "    axs[int(number_of_rows - 1), col].set_xlabel(\"Year\")\n",
    "\n",
    "axs[0, 0].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2395cf3-3c02-4a1d-affb-da53af44ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define observation simulation times for each link (separated by steps of one minute)\n",
    "observation_times = np.arange(epoch_start_nobuffer, epoch_end_nobuffer, 60)\n",
    "observation_simulation_settings = list()\n",
    "\n",
    "for link in link_list:\n",
    "    observation_simulation_settings.append(observation.tabulated_simulation_settings(\n",
    "        observation.angular_position_type,\n",
    "        link,\n",
    "        observation_times))\n",
    "\n",
    "noise_level = 1e-5\n",
    "observation.add_gaussian_noise_to_observable(\n",
    "    observation_simulation_settings,\n",
    "    noise_level,\n",
    "    observation.angular_position_type\n",
    ")\n",
    "\n",
    "# Create viability setting\n",
    "### Integrator and Termination Settings ###\n",
    "# Create integrator settings\n",
    "integrator_settings = propagation_setup.integrator.\\\n",
    "    runge_kutta_fixed_step_size(initial_time_step=60,\n",
    "                                coefficient_set=propagation_setup.integrator.CoefficientSets.rkdp_87)\n",
    "# Create termination settings\n",
    "termination_settings = propagation_setup.propagator.time_termination(epoch_end_nobuffer)\n",
    "\n",
    "### Propagator Settings ###\n",
    "propagator_settings_simulation = propagation_setup.propagator. \\\n",
    "    translational(central_bodies=central_bodies,\n",
    "                  acceleration_models=acceleration_models,\n",
    "                  bodies_to_integrate=bodies_to_propagate,\n",
    "                  initial_states=initial_guess_spice,\n",
    "                  initial_time=epoch_start_buffer,\n",
    "                  integrator_settings=integrator_settings,\n",
    "                  termination_settings=termination_settings)\n",
    "\n",
    "propagator_settings_simulation.processing_settings.set_integrated_result = True\n",
    "\n",
    "\n",
    "# Create observation simulators\n",
    "observation_simulators = estimation_setup.create_observation_simulators(\n",
    "    observation_settings_list, bodies)\n",
    "# Get JUICE simulated observations as ObservationCollection\n",
    "juice_simulated_observations = estimation.simulate_observations(\n",
    "    observation_simulation_settings,\n",
    "    observation_simulators,\n",
    "    bodies)\n",
    "\n",
    "#print(np.degrees(juice_simulated_observations.concatenated_observations))\n",
    "observation_times = np.unique(observation_collection.concatenated_times)\n",
    "\n",
    "RA_obs_list = []\n",
    "RA_sim_list = []\n",
    "DEC_obs_list = []\n",
    "DEC_sim_list = []\n",
    "\n",
    "for j,i in enumerate(observation_collection.concatenated_observations):\n",
    "    if (j % 2) == 0:\n",
    "        RA_obs_list.append(observation_collection.concatenated_observations[j])\n",
    "        RA_sim_list.append(juice_simulated_observations.concatenated_observations[j])\n",
    "    elif j == 181:\n",
    "        DEC_obs_list.append(observation_collection.concatenated_observations[j])\n",
    "        DEC_sim_list.append(juice_simulated_observations.concatenated_observations[j])\n",
    "    else:\n",
    "        DEC_obs_list.append(observation_collection.concatenated_observations[j])\n",
    "        DEC_sim_list.append(juice_simulated_observations.concatenated_observations[j])\n",
    "\n",
    "\n",
    "plt.scatter(np.degrees(RA_obs_list), np.degrees(DEC_obs_list), label = 'data', s = 20)\n",
    "plt.scatter(np.degrees(RA_sim_list), np.degrees(DEC_sim_list), label = 'simulated', s=20)\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('DEC')\n",
    "plt.legend()\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 2, figsize=(9, 6))\n",
    "\n",
    "ax1[0].scatter(np.degrees(RA_obs_list), np.degrees(DEC_obs_list), label = 'data', s = 20)\n",
    "ax1[0].scatter(np.degrees(RA_sim_list), np.degrees(DEC_sim_list), label = 'simulated', s=20)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax1[1].scatter(observation_times, np.degrees(DEC_obs_list), label = 'data DEC', s = 20)\n",
    "ax1[1].scatter(batch_times, np.degrees(DEC_sim_list), label = 'simulated DEC', s=20)\n",
    "ax1[1].scatter(observation_times, np.degrees(RA_obs_list), label = 'data RA', s = 20)\n",
    "ax1[1].scatter(batch_times, np.degrees(RA_sim_list), label = 'simulated RA', s=20)\n",
    "\n",
    "\n",
    "ax1[0].set_xlabel(r'RA deg')\n",
    "ax1[0].set_ylabel(r'DEC deg')\n",
    "ax1[1].set_xlabel(r'Time')\n",
    "ax1[1].set_ylabel(r'Angular Coord.')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2de893-ceca-40d7-9247-4587d8cf3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corellation can be retrieved using the CovarianceAnalysisInput class:\n",
    "covariance_input = estimation.CovarianceAnalysisInput(observation_collection)\n",
    "covariance_output = estimator.compute_covariance(covariance_input)\n",
    "\n",
    "correlations = covariance_output.correlations\n",
    "estimated_param_names = [\"x\", \"y\", \"z\", \"vx\", \"vy\", \"vz\"]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 7))\n",
    "\n",
    "im = ax.imshow(correlations, cmap=cm.RdYlBu_r, vmin=-1, vmax=1)\n",
    "\n",
    "ax.set_xticks(np.arange(len(estimated_param_names)), labels=estimated_param_names)\n",
    "ax.set_yticks(np.arange(len(estimated_param_names)), labels=estimated_param_names)\n",
    "\n",
    "# add numbers to each of the boxes\n",
    "for i in range(len(estimated_param_names)):\n",
    "    for j in range(len(estimated_param_names)):\n",
    "        text = ax.text(\n",
    "            j, i, round(correlations[i, j], 4), ha=\"center\", va=\"center\", color=\"w\"\n",
    "        )\n",
    "\n",
    "cb = plt.colorbar(im)\n",
    "\n",
    "ax.set_xlabel(\"Estimated Parameter\")\n",
    "ax.set_ylabel(\"Estimated Parameter\")\n",
    "\n",
    "fig.suptitle(f\"Correlations for estimated parameters for {'JUICE'}\")\n",
    "\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47602ba0-5c87-4aa4-b98d-9cc806476c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator_object = estimation_output.simulation_results_per_iteration[-1]\n",
    "print(simulator_object)\n",
    "state_history = simulator_object.dynamics_results.state_history\n",
    "state_history_simulated_observations = dynamics_simulator.state_history\n",
    "\n",
    "time2plt = np.vstack(list(state_history.keys()))\n",
    "time2plt_normalized = (time2plt - time2plt[0]) / (3600*24)\n",
    "\n",
    "juice_prop = np.vstack(list(state_history.values()))\n",
    "juice_sim_obs = np.vstack(list(state_history_simulated_observations.values()))\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(9, 6))\n",
    "\n",
    "ax1.plot(time2plt_normalized, (juice_prop[:, 0] - juice_sim_obs[:, 0]), label=r'$\\Delta x$')\n",
    "ax1.plot(time2plt_normalized, (juice_prop[:, 1] - juice_sim_obs[:, 1]), label=r'$\\Delta y$')\n",
    "ax1.plot(time2plt_normalized, (juice_prop[:, 2] - juice_sim_obs[:, 2]), label=r'$\\Delta z$')\n",
    "ax1.plot(time2plt_normalized, np.linalg.norm((juice_prop[:, 0:3] - juice_sim_obs[:, 0:3]), axis=1), label=r'$||\\Delta X||$')\n",
    "\n",
    "ax1.set_title(\"Element-wise difference between true and estimated states\")\n",
    "ax1.set_xlabel(r'$Time$ [days]')\n",
    "ax1.set_ylabel(r'$\\Delta X$ [m]')\n",
    "ax1.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d681a8-78fd-4958-b021-a5bb896fd456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tudat-space",
   "language": "python",
   "name": "tudat-space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
